# æç¤ºè¯ä½¿ç”¨æŒ‡å—

## ğŸ“ æ¦‚è¿°

æœ¬é¡¹ç›®ä½¿ç”¨æ–‡ä»¶åŒ–çš„æç¤ºè¯ç®¡ç†ç³»ç»Ÿï¼Œæ‰€æœ‰æç¤ºè¯å­˜å‚¨åœ¨ `app/prompts/` ç›®å½•ä¸‹ï¼Œæ”¯æŒåŠ¨æ€åŠ è½½ã€ç¼“å­˜å’Œå˜é‡æ›¿æ¢ã€‚

## ğŸ“ æç¤ºè¯æ–‡ä»¶

### å½“å‰æç¤ºè¯

1. **literature-guide-system-prompt.txt**
   - ç”¨é€”ï¼šç”Ÿæˆæ–‡çŒ®é˜…è¯»æŒ‡å—çš„ç³»ç»Ÿæç¤ºè¯
   - åŒ…å«ï¼šè§’è‰²å®šä¹‰ã€å·¥ä½œæµç¨‹ã€è¾“å‡ºæ ¼å¼è¦æ±‚
   - ä½¿ç”¨åœºæ™¯ï¼šAI ç”Ÿæˆé˜…è¯»æŒ‡å—æ—¶çš„ç³»ç»ŸæŒ‡ä»¤

2. **literature-classification-system-prompt.txt**
   - ç”¨é€”ï¼šä»é˜…è¯»æŒ‡å—ä¸­æå–æ ‡ç­¾å’Œæè¿°
   - åŒ…å«ï¼šåˆ†ç±»è§„åˆ™ã€è¾“å‡ºæ ¼å¼ã€JSON æ ¼å¼è¦æ±‚
   - ä½¿ç”¨åœºæ™¯ï¼šè‡ªåŠ¨åˆ†ç±»å’Œæ ‡ç­¾æå–

## ğŸ”§ ä½¿ç”¨æ–¹æ³•

### æ–¹æ³•ä¸€ï¼šç›´æ¥åŠ è½½ï¼ˆæ¨èï¼‰

```python
from app.utils.prompt_loader import load_prompt

# åŠ è½½æç¤ºè¯ï¼ˆè‡ªåŠ¨ç¼“å­˜ï¼‰
system_prompt = load_prompt("literature-guide-system-prompt")

# ä½¿ç”¨æç¤ºè¯
messages = [
    {"role": "system", "content": system_prompt},
    {"role": "user", "content": user_input}
]
```

### æ–¹æ³•äºŒï¼šä½¿ç”¨è£…é¥°å™¨

```python
from app.utils.prompt_loader import with_prompt

@with_prompt("literature-guide-system-prompt", param_name="system_prompt")
async def generate_guide(content: str, system_prompt: str = None):
    # system_prompt ä¼šè¢«è‡ªåŠ¨æ³¨å…¥
    print(system_prompt)  # å·²åŠ è½½çš„æç¤ºè¯å†…å®¹
    # ... ä¸šåŠ¡é€»è¾‘
```

### æ–¹æ³•ä¸‰ï¼šä½¿ç”¨ PromptLoader å®ä¾‹

```python
from app.utils.prompt_loader import PromptLoader

# åˆ›å»ºåŠ è½½å™¨
loader = PromptLoader()

# åŠ è½½æç¤ºè¯
prompt = loader.load_prompt("literature-guide-system-prompt")

# æ”¯æŒå˜é‡æ›¿æ¢
prompt_with_vars = loader.get_prompt(
    "some-prompt-with-variables",
    variable1="value1",
    variable2="value2"
)

# é‡æ–°åŠ è½½ï¼ˆæ¸…é™¤ç¼“å­˜ï¼‰
fresh_prompt = loader.reload_prompt("literature-guide-system-prompt")
```

## ğŸ“– å®é™…åº”ç”¨ç¤ºä¾‹

### ç¤ºä¾‹1ï¼šåœ¨ AI æœåŠ¡ä¸­ä½¿ç”¨

```python
# app/services/ai_service.py

from app.utils.prompt_loader import load_prompt

class AIService:
    async def generate_reading_guide_stream(self, content: str, api_key: str):
        # åŠ è½½ç³»ç»Ÿæç¤ºè¯
        system_prompt = load_prompt("literature-guide-system-prompt")
        
        # æ„å»ºæ¶ˆæ¯
        messages = [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": f"è¯·ä¸ºä»¥ä¸‹æ–‡çŒ®ç”Ÿæˆé˜…è¯»æŒ‡å—ï¼š\n\n{content}"}
        ]
        
        # è°ƒç”¨ AI API
        # ...
```

### ç¤ºä¾‹2ï¼šæå–æ ‡ç­¾å’Œæè¿°

```python
# app/services/ai_service.py

async def extract_tags_and_description(self, reading_guide: str):
    # åŠ è½½åˆ†ç±»æç¤ºè¯
    system_prompt = load_prompt("literature-classification-system-prompt")
    
    messages = [
        {"role": "system", "content": system_prompt},
        {"role": "user", "content": f"æ–‡çŒ®é˜…è¯»æŒ‡å—ï¼š\n\n{reading_guide}"}
    ]
    
    # è°ƒç”¨ AI API æå–
    # ...
```

## ğŸ¯ æç¤ºè¯å˜é‡æ›¿æ¢

å¦‚æœæç¤ºè¯ä¸­åŒ…å«å˜é‡å ä½ç¬¦ï¼ˆä½¿ç”¨ `{variable_name}` æ ¼å¼ï¼‰ï¼Œå¯ä»¥è¿™æ ·ä½¿ç”¨ï¼š

### åˆ›å»ºå¸¦å˜é‡çš„æç¤ºè¯æ–‡ä»¶

```text
# my-prompt-with-vars.txt

ä½ æ˜¯ä¸€ä½{role}ï¼Œä¸“é•¿äº{specialty}ã€‚

è¯·å¸®åŠ©ç”¨æˆ·å®Œæˆä»¥ä¸‹ä»»åŠ¡ï¼š{task}
```

### ä½¿ç”¨æ—¶æ›¿æ¢å˜é‡

```python
from app.utils.prompt_loader import load_prompt

prompt = load_prompt(
    "my-prompt-with-vars",
    role="æ•°æ®åˆ†æå¸ˆ",
    specialty="ç»Ÿè®¡å»ºæ¨¡å’Œæ•°æ®å¯è§†åŒ–",
    task="åˆ†æé”€å”®æ•°æ®è¶‹åŠ¿"
)

print(prompt)
# è¾“å‡ºï¼š
# ä½ æ˜¯ä¸€ä½æ•°æ®åˆ†æå¸ˆï¼Œä¸“é•¿äºç»Ÿè®¡å»ºæ¨¡å’Œæ•°æ®å¯è§†åŒ–ã€‚
# è¯·å¸®åŠ©ç”¨æˆ·å®Œæˆä»¥ä¸‹ä»»åŠ¡ï¼šåˆ†æé”€å”®æ•°æ®è¶‹åŠ¿
```

## ğŸ“‹ æç¤ºè¯å‘½åè§„èŒƒ

- ä½¿ç”¨å°å†™å­—æ¯å’Œè¿å­—ç¬¦
- æè¿°æ€§å‘½åï¼Œæ¸…æ™°è¡¨è¾¾ç”¨é€”
- ç»Ÿä¸€ä½¿ç”¨ `.txt` æ‰©å±•å

ç¤ºä¾‹ï¼š
- âœ… `literature-guide-system-prompt.txt`
- âœ… `literature-classification-system-prompt.txt`
- âœ… `error-analysis-prompt.txt`
- âŒ `prompt1.txt`
- âŒ `GUIDE_PROMPT.txt`

## ğŸ”„ æç¤ºè¯ç¼“å­˜æœºåˆ¶

æç¤ºè¯åŠ è½½å™¨ä½¿ç”¨ `@lru_cache` è£…é¥°å™¨å®ç°ç¼“å­˜ï¼š

- **é¦–æ¬¡åŠ è½½**ï¼šä»æ–‡ä»¶è¯»å–å¹¶ç¼“å­˜
- **åç»­åŠ è½½**ï¼šç›´æ¥ä»ç¼“å­˜è¿”å›ï¼ˆæå‡æ€§èƒ½ï¼‰
- **ç¼“å­˜å¤§å°**ï¼šæœ€å¤šç¼“å­˜ 32 ä¸ªæç¤ºè¯
- **æ‰‹åŠ¨æ¸…é™¤**ï¼šä½¿ç”¨ `reload_prompt()` æ–¹æ³•

```python
from app.utils.prompt_loader import prompt_loader

# æ¸…é™¤ç‰¹å®šæç¤ºè¯ç¼“å­˜
prompt_loader.reload_prompt("literature-guide-system-prompt")

# æ¸…é™¤æ‰€æœ‰ç¼“å­˜
prompt_loader.load_prompt.cache_clear()
```

## ğŸ› ï¸ æœ€ä½³å®è·µ

### 1. æç¤ºè¯ç‰ˆæœ¬ç®¡ç†

ä¸ºé‡è¦çš„æç¤ºè¯åˆ›å»ºç‰ˆæœ¬å¤‡ä»½ï¼š

```
app/prompts/
â”œâ”€â”€ literature-guide-system-prompt.txt       # å½“å‰ç‰ˆæœ¬
â”œâ”€â”€ literature-guide-system-prompt-v1.txt    # å¤‡ä»½ç‰ˆæœ¬1
â””â”€â”€ literature-guide-system-prompt-v2.txt    # å¤‡ä»½ç‰ˆæœ¬2
```

### 2. æç¤ºè¯æµ‹è¯•

åœ¨ä¿®æ”¹æç¤ºè¯åï¼Œå»ºè®®è¿›è¡Œæµ‹è¯•ï¼š

```python
# tests/test_prompts.py

def test_prompt_loading():
    from app.utils.prompt_loader import load_prompt
    
    # æµ‹è¯•åŠ è½½
    prompt = load_prompt("literature-guide-system-prompt")
    assert prompt is not None
    assert len(prompt) > 0
    
    # æµ‹è¯•å†…å®¹
    assert "Role:" in prompt
    assert "Workflow:" in prompt
```

### 3. æç¤ºè¯æ–‡æ¡£åŒ–

åœ¨æç¤ºè¯æ–‡ä»¶å¼€å¤´æ·»åŠ æ³¨é‡Šè¯´æ˜ï¼š

```text
# literature-guide-system-prompt.txt
# ç”¨é€”ï¼šç”Ÿæˆæ–‡çŒ®é˜…è¯»æŒ‡å—çš„ç³»ç»Ÿæç¤ºè¯
# ç‰ˆæœ¬ï¼šv1.0
# æœ€åæ›´æ–°ï¼š2024-11-10
# ä½œè€…ï¼šLiterature Assistant Team

# Role: èµ„æ·±å­¦æœ¯å¯¼å¸ˆ
...
```

### 4. æ¨¡å—åŒ–æç¤ºè¯

å¯¹äºå¤æ‚çš„æç¤ºè¯ï¼Œå¯ä»¥æ‹†åˆ†ä¸ºå¤šä¸ªæ–‡ä»¶ï¼š

```python
from app.utils.prompt_loader import load_prompt

# åŠ è½½å¤šä¸ªæç¤ºè¯ç‰‡æ®µ
role_prompt = load_prompt("role-definition")
workflow_prompt = load_prompt("workflow-steps")
output_format_prompt = load_prompt("output-format")

# ç»„åˆä½¿ç”¨
full_prompt = f"{role_prompt}\n\n{workflow_prompt}\n\n{output_format_prompt}"
```

## ğŸ” è°ƒè¯•æŠ€å·§

### æŸ¥çœ‹åŠ è½½çš„æç¤ºè¯

```python
from app.utils.prompt_loader import load_prompt

prompt = load_prompt("literature-guide-system-prompt")
print("=" * 50)
print("æç¤ºè¯å†…å®¹ï¼š")
print("=" * 50)
print(prompt)
print("=" * 50)
print(f"æç¤ºè¯é•¿åº¦ï¼š{len(prompt)} å­—ç¬¦")
```

### éªŒè¯æç¤ºè¯æ–‡ä»¶

```python
from pathlib import Path

prompts_dir = Path("app/prompts")
print("å¯ç”¨çš„æç¤ºè¯æ–‡ä»¶ï¼š")
for prompt_file in prompts_dir.glob("*.txt"):
    print(f"  - {prompt_file.name}")
```

## ğŸ“š ç›¸å…³èµ„æº

- æç¤ºè¯ç¼–å†™æŒ‡å—ï¼š[OpenAI Best Practices](https://platform.openai.com/docs/guides/prompt-engineering)
- Markdown æ ¼å¼è§„èŒƒï¼š[CommonMark Spec](https://commonmark.org/)
- Mermaid å›¾è¡¨è¯­æ³•ï¼š[Mermaid Documentation](https://mermaid.js.org/)

## â“ å¸¸è§é—®é¢˜

### Q: å¦‚ä½•æ·»åŠ æ–°çš„æç¤ºè¯ï¼Ÿ

A: åœ¨ `app/prompts/` ç›®å½•ä¸‹åˆ›å»ºæ–°çš„ `.txt` æ–‡ä»¶ï¼Œç„¶åä½¿ç”¨ `load_prompt()` åŠ è½½å³å¯ã€‚

### Q: æç¤ºè¯æ–‡ä»¶æ‰¾ä¸åˆ°æ€ä¹ˆåŠï¼Ÿ

A: æ£€æŸ¥ä»¥ä¸‹å‡ ç‚¹ï¼š
1. æ–‡ä»¶æ˜¯å¦åœ¨ `app/prompts/` ç›®å½•ä¸‹
2. æ–‡ä»¶æ‰©å±•åæ˜¯å¦ä¸º `.txt`
3. æ–‡ä»¶åæ˜¯å¦æ­£ç¡®ï¼ˆåŒºåˆ†å¤§å°å†™ï¼‰

### Q: å¦‚ä½•æ›´æ–°å·²ç¼“å­˜çš„æç¤ºè¯ï¼Ÿ

A: ä½¿ç”¨ `reload_prompt()` æ–¹æ³•ï¼š
```python
from app.utils.prompt_loader import prompt_loader
prompt_loader.reload_prompt("your-prompt-name")
```

### Q: æ”¯æŒå…¶ä»–æ ¼å¼çš„æç¤ºè¯æ–‡ä»¶å—ï¼Ÿ

A: ç›®å‰åªæ”¯æŒ `.txt` æ ¼å¼ã€‚å¦‚æœéœ€è¦å…¶ä»–æ ¼å¼ï¼Œå¯ä»¥ä¿®æ”¹ `PromptLoader` ç±»çš„ `load_prompt()` æ–¹æ³•ã€‚

---

**æœ€åæ›´æ–°**: 2024-11-10
**ç»´æŠ¤è€…**: Literature Assistant Team

